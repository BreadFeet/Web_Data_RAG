{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Building a RAG system for web data using Llama 3.1-405b](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This project builds upon the [Create a LangChain RAG system for web data in Python using Llama 3.1-405b in watsonx.ai](https://developer.ibm.com/tutorials/awb-create-langchain-rag-system-web-data-llama405b-watsonx/) tutorial authored by Erika Russi.\n",
    "\n",
    "Estimated time needed: **30** minutes\n",
    "\n",
    "In this guided project, we will use LangChain and `meta-llama/llama-3-405b-instruct` to walk through a step-by-step Retrieval Augmented Generation ([RAG](https://research.ibm.com/blog/retrieval-augmented-generation-RAG?utm_source=skills_network&utm_content=in_lab_content_link&utm_id=Lab-Building+a+RAG+system+for+web+data+using+Llama+3.1-405b_v1_1722347683)) example in Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "\n",
    "  - [Introduction](#toc1_1_)    \n",
    "  - [What does this guided project do?](#toc1_2_)    \n",
    "  - [Objectives](#toc1_3_)    \n",
    "  - [Background](#toc1_4_)    \n",
    "    - [What is Large Language Model (LLM)?](#toc1_4_1_)    \n",
    "    - [What is IBM watsonx?](#toc1_4_2_)    \n",
    "    - [Why watsonx vs other cloud platforms?](#toc1_4_3_)    \n",
    "    - [What is LangChain?](#toc1_4_4_)    \n",
    "    - [What is Llama 3.1-405b?](#toc1_4_5_)    \n",
    "    - [What is Retrieval Augmented Generation (RAG)?](#toc1_4_6_)    \n",
    "    - [More about RAG and LangChain](#toc1_4_7_)    \n",
    "  - [Setup](#toc1_5_)    \n",
    "    - [Installing required libraries](#toc1_5_1_)    \n",
    "  - [Watsonx API credentials and project_id](#toc1_6_)    \n",
    "  - [Index the URLs to create the knowledge base](#toc1_7_)    \n",
    "  - [Set up a retriever](#toc1_8_)    \n",
    "  - [Generate a response with a generative model](#toc1_9_)    \n",
    "  - [Exercises](#toc1_10_)    \n",
    "    - [Exercise 1 - ask more questions](#toc1_10_1_)     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Introduction](#toc0_)\n",
    "\n",
    "Imagine you have several web pages, and want to extract information from them. You could read each page and take notes, but that would be time-consuming. Instead, you can use a RAG system to help you. RAG systems combine the power of a large language model (LLM) with a retrieval system to provide context to the LLM. This allows you to ask questions about the content of the web pages and get answers quickly.\n",
    "\n",
    "\n",
    "## <a id='toc1_2_'></a>[What does this guided project do?](#toc0_)\n",
    "\n",
    "We will set up a local RAG system for several IBM products. We will fetch content from web pages, making up a knowledge base from which we will provide context to Meta's Llama 3.1-405b LLM to answer some questions about these IBM products.\n",
    "\n",
    "\n",
    "## <a id='toc1_3_'></a>[Objectives](#toc0_)\n",
    "\n",
    "After completing this lab, you will be able to:\n",
    "\n",
    "- Understand how to set up and configure LangChain for advanced language modeling tasks.\n",
    "- Learn to use Llama 3.1-405b on watsonx.ai to enhance your language model's capabilities.\n",
    "- Develop a RAG system to generate context-aware, real-time responses from web data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[Background](#toc0_)\n",
    "\n",
    "### <a id='toc1_4_1_'></a>[What is Large Language Model (LLM)?](#toc0_)\n",
    "\n",
    "[Large language models](https://www.ibm.com/topics/large-language-models?utm_source=skills_network&utm_content=in_lab_content_link&utm_id=Lab-Build+a+RAG+system+for+web+data+using+Llama+3.1-405b_v1_1727723829) are a category of foundation models trained on immense amounts of data making them capable of understanding and generating natural language and other types of content to perform a wide range of tasks.\n",
    "\n",
    "### <a id='toc1_4_2_'></a>[What is IBM watsonx?](#toc0_)\n",
    "\n",
    "[IBM watsonx](https://www.ibm.com/watsonx?utm_source=skills_network&utm_content=in_lab_content_link&utm_id=Lab-Build+a+RAG+system+for+web+data+using+Llama+3.1-405b_v1_1727723829) is a suite of artificial intelligence (AI) tools and services that are designed to help developers build and deploy AI-driven applications. watsonx provides a range of APIs and tools that make it easy to integrate AI capabilities into applications, including natural language processing, computer vision, and speech recognition.\n",
    "\n",
    "**Enterprises  turn to watsonx because it is:**\n",
    "\n",
    "- **Open**: Based on open technologies that provide a variety of models to cover enterprise use cases and support compliance initiatives.\n",
    "- **Targeted**: Targeted to specific enterprise domains like HR, customer service or IT operations to unlock new value.\n",
    "- **Trusted**: Designed with principles of transparency, responsibility, and governance, so that you can manage  ethical and accuracy concerns.\n",
    "- **Empowering**: Go beyond being an AI user and become an AI value creator, owning the value your models create.\n",
    "\n",
    "### <a id='toc1_4_3_'></a>[Why watsonx vs other cloud platforms?](#toc0_)\n",
    "\n",
    "- **Infrastructure**: watsonx offers hybrid, multi-cloud option for model deployment.\n",
    "- **Models**: watsonx's ability to deliver on-premise. watsonx offers deployment flexibility and additional safeguards when working with proprietary data not suited for a 3rd party cloud.\n",
    "- **Platform**: watsonx is not just watsonx.ai – it is also watsonx.data and watsonx.governance, adding data control/management and data/AI governance. This gives clients an infrastructure that allows them to develop/deploy and govern the data and the AI model being used.\n",
    "\n",
    "\n",
    "### <a id='toc1_4_4_'></a>[What is LangChain?](#toc0_)\n",
    "\n",
    "[LangChain](https://www.ibm.com/topics/langchain?utm_source=skills_network&utm_content=in_lab_content_link&utm_id=Lab-Build+a+RAG+system+for+web+data+using+Llama+3.1-405b_v1_1727723829) is an open source orchestration framework for the development of applications using LLMs. Available in both Python- and JavaScript-based libraries, LangChain’s tools and APIs simplify the process of building LLM-driven applications like [chatbots](https://www.ibm.com/topics/chatbots?utm_source=skills_network&utm_content=in_lab_content_link&utm_id=Lab-Build+a+RAG+system+for+web+data+using+Llama+3.1-405b_v1_1727723829) and [virtual agents](https://www.ibm.com/topics/virtual-agent?utm_source=skills_network&utm_content=in_lab_content_link&utm_id=Lab-Build+a+RAG+system+for+web+data+using+Llama+3.1-405b_v1_1727723829). \n",
    "\n",
    "### <a id='toc1_4_5_'></a>[What is Llama 3.1-405b?](#toc0_)\n",
    "\n",
    "[On Tuesday, July 23, 2024, Meta announced the launch of the Llama 3.1 collection of multilingual large language models (LLMs)](https://www.ibm.com/blog/meta-releases-llama-3-1-models-405b-parameter-variant/?utm_source=skills_network&utm_content=in_lab_content_link&utm_id=Lab-Build+a+RAG+system+for+web+data+using+Llama+3.1-405b_v1_1727723829). Llama 3.1 comprises both pretrained and instruction-tuned text in/text out open source generative AI models in sizes of 8B, 70B and—for the first time—405B parameters. Llama-3.1-405B is one of the world’s largest and most powerful open models. \n",
    "\n",
    "Powered by 405 billion parameters, this model specializes in generating synthetic data, distilling knowledge into smaller models, domain-specific fine-tuning and evaluating other models’ responses. Its performance either matches or surpasses leading large language models in a variety of tests assessing undergraduate level knowledge, graduate level reasoning, math problem solving, reading comprehension, and more.\n",
    "\n",
    "Unlike its closed source peers, Llama-3.1-405B is open source, meaning it can be built upon and improved by the broader community.\n",
    "\n",
    "More information about Llama 3.1-405b can be found [here](https://ai.meta.com/blog/meta-llama-3-1/).\n",
    "\n",
    "### <a id='toc1_4_6_'></a>[What is Retrieval Augmented Generation (RAG)?](#toc0_)\n",
    "\n",
    "[RAG](https://research.ibm.com/blog/retrieval-augmented-generation-RAG?utm_source=skills_network&utm_content=in_lab_content_link&utm_id=Lab-Build+a+RAG+system+for+web+data+using+Llama+3.1-405b_v1_1727723829) is a technique in natural language processing (NLP) that combines information retrieval and generative models to produce more accurate, relevant, and contextually aware responses.\n",
    "\n",
    "### <a id='toc1_4_7_'></a>[More about RAG and LangChain](#toc0_)\n",
    "\n",
    "In traditional language generation tasks, LLMs, such as OpenAI’s GPT (Generative Pre-trained Transformer) or IBM’s Granite Models, are used to construct responses based on an input prompt. However, these models can struggle to produce responses that are contextually relevant, factually accurate, or up-to-date. The models may not know the latest information about IBM products.\n",
    "\n",
    "RAG applications address this limitation by incorporating a retrieval step before response generation. During retrieval, [vector search](https://www.ibm.com/topics/vector-search?utm_source=skills_network&utm_content=in_lab_content_link&utm_id=Lab-Build+a+RAG+system+for+web+data+using+Llama+3.1-405b_v1_1727723829) can be used to identify contextually pertinent information, such as relevant information or documents from a large corpus of text, typically stored in a [vector database](https://www.ibm.com/topics/vector-database?utm_source=skills_network&utm_content=in_lab_content_link&utm_id=Lab-Build+a+RAG+system+for+web+data+using+Llama+3.1-405b_v1_1727723829). Finally, an LLM is used to generate a response based on the retrieved context. RAG is an affordable and simple alternative to [fine-tuning](https://www.ibm.com/topics/fine-tuning?utm_source=skills_network&utm_content=in_lab_content_link&utm_id=Lab-Build+a+RAG+system+for+web+data+using+Llama+3.1-405b_v1_1727723829) a model for text-generation artificial intelligence tasks.\n",
    "\n",
    "LangChain is a powerful, open-source framework that facilitates the development of applications using LLMs for various NLP tasks. In the context of RAG, LangChain plays a critical role by combining the strengths of retrieval-based methods and generative models to enhance the capabilities of NLP systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_5_'></a>[Setup](#toc0_)\n",
    "\n",
    "For this lab, we will be using the following libraries:\n",
    "\n",
    "\n",
    "*   [`langchain`](https://pypi.org/project/langchain/): Building applications with LLMs through composability.\n",
    "*   [`ibm-watsonx-ai`](https://pypi.org/project/ibm-watsonx-ai/): `ibm-watsonx-ai` is a library that allows to work with watsonx.ai service on IBM Cloud and IBM Cloud for Data. Train, test, and deploy your models as APIs for application development and share with colleagues using this python library.\n",
    "*   [`langchain-ibm`](https://pypi.org/project/langchain-ibm/): This package provides the integration between LangChain and IBM watsonx.ai through the ibm-watsonx-ai SDK.\n",
    "*   [`unstructured`](https://pypi.org/project/unstructured/): A library that prepares raw documents for downstream ML tasks.\n",
    "*   [`ibm-watson-machine-learning`](https://pypi.org/project/ibm-watson-machine-learning/): A library that allows to work with Watson Machine Learning service on IBM Cloud and IBM Cloud for Data. Train, test, and deploy your models as APIs for application development and share with colleagues using this python library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_5_1_'></a>[Installing required libraries](#toc0_)\n",
    "\n",
    "The following required libraries are __not__ pre-installed in the Skills Network Labs environment. __You must run the following cell__ to install them. Please wait until it completes.\n",
    "\n",
    "This step could take **several minutes**, please be patient.\n",
    "\n",
    "**NOTE**: If you encounter any issues, please restart the kernel and run again.  You can do that by clicking the **Restart the kernel** icon.\n",
    "\n",
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/crvBKBOkg9aBzXZiwGEXbw/Restarting-the-Kernel.png\" width=\"50%\" alt=\"Restart kernel\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed langchain-0.2.6 langchain-core-0.2.43 langchain-text-splitters-0.2.4 langsmith-0.1.147 numpy-1.26.4 orjson-3.10.18 requests-toolbelt-1.0.0 tenacity-8.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 cachetools-5.5.2 chroma-hnswlib-0.7.6 chromadb-0.5.23 click-8.1.8 coloredlogs-15.0.1 deprecated-1.2.18 durationpy-0.9 fastapi-0.115.12 filelock-3.18.0 flatbuffers-25.2.10 fsspec-2025.3.2 google-auth-2.39.0 googleapis-common-protos-1.70.0 grpcio-1.71.0 httptools-0.6.4 huggingface-hub-0.30.2 humanfriendly-10.0 kubernetes-32.0.1 langchain_chroma-0.1.2 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-5.1.0 mpmath-1.3.0 onnxruntime-1.21.1 opentelemetry-api-1.32.1 opentelemetry-exporter-otlp-proto-common-1.32.1 opentelemetry-exporter-otlp-proto-grpc-1.32.1 opentelemetry-instrumentation-0.53b1 opentelemetry-instrumentation-asgi-0.53b1 opentelemetry-instrumentation-fastapi-0.53b1 opentelemetry-proto-1.32.1 opentelemetry-sdk-1.32.1 opentelemetry-semantic-conventions-0.53b1 opentelemetry-util-http-0.53b1 posthog-4.0.1 protobuf-5.29.4 pyasn1-0.6.1 pyasn1-modules-0.4.2 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.1.0 requests-oauthlib-2.0.0 rich-14.0.0 rsa-4.9.1 shellingham-1.5.4 starlette-0.46.2 sympy-1.14.0 tokenizers-0.20.3 typer-0.15.3 uvicorn-0.34.2 uvloop-0.21.0 watchfiles-1.0.5 websockets-15.0.1 wrapt-1.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Successfully installed dataclasses-json-0.6.7 langchain-community-0.2.6 marshmallow-3.26.1 mypy-extensions-1.1.0 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Successfully installed ibm-cos-sdk-2.13.6 ibm-cos-sdk-core-2.13.6 ibm-cos-sdk-s3transfer-2.13.6 ibm-watsonx-ai-1.0.10 jmespath-1.0.1 lomond-0.3.3 pandas-2.1.4 requests-2.32.2 tabulate-0.9.0 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Successfully installed langchain_ibm-0.1.11\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Successfully installed aiofiles-24.1.0 chardet-5.2.0 emoji-2.14.1 eval-type-backport-0.2.2 filetype-1.2.0 joblib-1.5.0 langdetect-1.0.9 lxml-5.4.0 nltk-3.9.1 pydantic-2.11.4 pydantic-core-2.33.2 pypdf-5.4.0 python-iso639-2025.2.18 python-magic-0.4.27 rapidfuzz-3.13.0 regex-2024.11.6 typing-inspection-0.4.0 unstructured-0.15.0 unstructured-client-0.34.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Successfully installed ibm-watson-machine-learning-1.0.360\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain==0.2.6 | tail -n 1\n",
    "%pip install langchain_chroma==0.1.2 | tail -n 1\n",
    "%pip install langchain-community==0.2.6 | tail -n 1\n",
    "%pip install ibm-watsonx-ai==1.0.10 | tail -n 1\n",
    "%pip install langchain_ibm==0.1.11 | tail -n 1\n",
    "%pip install unstructured==0.15.0 | tail -n 1\n",
    "%pip install ibm-watson-machine-learning==1.0.360 | tail -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from ibm_watsonx_ai import Credentials\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_ibm import WatsonxEmbeddings\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import EmbeddingTypes\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "from langchain_ibm import WatsonxLLM\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "import pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_6_'></a>[Watsonx API credentials and project_id](#toc0_)\n",
    "\n",
    "This section provides you with the necessary credentials to access the watsonx API.\n",
    "\n",
    "**Please note:**\n",
    "\n",
    "In this lab environment, you don't need to specify the api_key, and the project_id is pre_set as \"skills-network\", but if you want to use the model locally, you need to go to [watsonx](https://www.ibm.com/watsonx?utm_source=skills_network&utm_content=in_lab_content_link&utm_id=Lab-Build+a+RAG+system+for+web+data+using+Llama+3.1-405b_v1_1727723829) to create your own keys and ID.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = Credentials(url='https://us-south.ml.cloud.ibm.com')\n",
    "project_id = 'skills-network'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials.get('apikey')   # Nothing printed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_7_'></a>[Index the URLs to create the knowledge base](#toc0_)\n",
    "\n",
    "We’ll index our IBM products specific pages from URLs to create a knowledge base as a vectorstore. The content from these URLs will be our data sources and context for this exercise. The context will then be provided to an LLM to answer any questions we have about the IBM products.\n",
    "\n",
    "The first step to building vector embeddings is to clean and process the raw dataset. This may involve the removal of noise and standardization of the text. For our example, we won’t do any cleaning since the text is already cleaned and standardized.\n",
    "\n",
    "First, let's establish `URLS_DICTIONARY`. `URLS_DICTIONARY` is a dict that helps us map the URLs from which we will be extracting the content. Let's also set up a name for our collection: `ibm_products`.\n",
    "\n",
    "Next, let's load our documents for the list of URLs we have. We'll print a sample document at the end to see how it's been loaded. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/PWMJ9-Npq9FYNSWrrf99YQ/watsonx.txt\n",
      "Loaded from https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/PWMJ9-Npq9FYNSWrrf99YQ/watsonx.txt\n",
      "Loading from https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/wxekgOAVRH71dO92DEbwfQ/ibm-cloud.txt\n",
      "Loaded from https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/wxekgOAVRH71dO92DEbwfQ/ibm-cloud.txt\n",
      "{'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/PWMJ9-Npq9FYNSWrrf99YQ/watsonx.txt', 'name': 'watsonx_wiki'}\n",
      "IBM Watsonx\\n\\nTÃ¼rkÃ§e\\n\\nEdit links\\n\\nFrom Wikipedia, the free encyclopedia\\n\\nAI platform developed by IBM\\n\\nFor the IBM question answering computer system, see IBM Watson.\\n\\nDeveloper(s) IBM Initial release May\\xa09, 2023 ; 14 months ago ( 2023-05-09 ) [1] Written in Python Engine Multiple large language models (LLMs) Platform Cloud computing platforms Type Chatbot AI fine-tuning of large language models Generative pre-trained transformer (GPT) License Proprietary Website www .ibm .com /watsonx\\n\\nPart of a series on Machine learning and data mining Paradigms Supervised learning Unsupervised learning Online learning Batch learning Meta-learning Semi-supervised learning Self-supervised learning Reinforcement learning Curriculum learning Rule-based learning Quantum machine learning Neuromorphic engineering Problems Classification Generative modeling Regression Clustering Dimensionality reduction Density estimation Anomaly detection Data cleaning AutoML Association rules Semantic analysis Structured prediction Feature engineering Feature learning Learning to rank Grammar induction Ontology learning Multimodal learning Supervised learning ( classification â¢ regression ) Apprenticeship learning Decision trees Ensembles Bagging Boosting Random forest k -NN Linear regression Naive Bayes Artificial neural networks Logistic regression Perceptron Relevance vector machine (RVM) Support vector machine (SVM) Clustering BIRCH CURE Hierarchical k -means Fuzzy Expectationâmaximization (EM) DBSCAN OPTICS Mean shift Dimensionality reduction Factor analysis CCA ICA LDA NMF PCA PGD t-SNE SDL Structured prediction Graphical models Bayes net Conditional random field Hidden Markov Anomaly detection RANSAC k -NN Local outlier factor Isolation forest Artificial neural network Autoencoder Deep learning Feedforward neural network Recurrent neural network LSTM GRU ESN reservoir computing Boltzmann machine Restricted GAN Diffusion model SOM Convolutional neural network U-Net LeNet AlexNet DeepDream Neural radiance field Transformer Vision Mamba Spiking neural network Memtransistor Electrochemical RAM (ECRAM) Reinforcement learning Q-learning SARSA Temporal difference (TD) Multi-agent Self-play Learning with humans Active learning Crowdsourcing Human-in-the-loop RLHF Model diagnostics Coefficient of determination Confusion matrix Learning curve ROC curve Mathematical foundations Kernel machines Biasâvariance tradeoff Computational learning theory Empirical risk minimization Occam learning PAC learning Statistical learning VC theory Journals and conferences ECML PKDD NeurIPS ICML ICLR IJCAI ML JMLR Related articles Glossary of artificial intelligence List of datasets for machine-learning research List of datasets in computer vision and image processing Outline of machine learning v t e\\n\\nWatsonx is IBM\\'s commercial generative AI and scientific data platform based on cloud. It offers a studio, data store, and governance toolkit. It supports multiple large language models (LLMs) along with IBM\\'s own Granite.[2][1]\\n\\nThe platform is described as an AI tool tailed to companies and a one which can be customized for customers\\' needs and trained on their confidential data, as client data is said to be not collected by IBM for further training of their models. It is also capable of fine-tuning, an approach which makes training pre-trained models on the newly introduced data possible.[3]\\n\\nHistory\\n\\n[edit]\\n\\nWatsonx was revealed on May 9, 2023, at the annual Think conference of IBM as a platform that includes multiple services. Just like Watson AI computer with the similar name, Watsonx was named after Thomas J. Watson, IBM\\'s founder and first CEO.[1]\\n\\nOn February 13, 2024, Anaconda partnered with IBM to embed its open-source Python packages into Watsonx.[4]\\n\\nWatsonx is currently used at ESPN\\'s Fantasy Football App for managing players\\' performance.[5] It is also used by Italian telecommunications company Wind Tre.[6] Watsonx was used to generate editorial content around nominees during the 66th Annual Grammy Awards.[7]\\n\\nServices\\n\\n[edit]\\n\\nwatsonx.ai\\n\\n[edit]\\n\\nWatsonx.ai is a platform that allows AI developers to leverage a wide range of LLMs under IBM\\'s own Granite series and others such as Facebook\\'s LLaMA-2, free and open-source model Mistral and many others present in Hugging Face community for a diverse set of AI development tasks.[8][9] These models come pre-trained and are designed to excel in various Natural Language Processing (NLP) applications, encompassing question answering, content generation, summarization, text classification, and data extraction. The platform allows fine-tuning with its Tuning Studio, allowing those models to learn the data provided by customers.[10]\\n\\nwatsonx.data\\n\\n[edit]\\n\\nWatsonx.data is a platform designed to assist clients in addressing issues related to data volume, complexity, cost, and governance as they scale their AI workloads. This platform facilitates seamless data access, whether the data is stored in the cloud or on-premises, through a single entry point, offering simple use for users who may not possess technical expertise. This approach prioritizes data security and compliance.[10]\\n\\nwatsonx.governance\\n\\n[edit]\\n\\nWatsonx.governance is a platform that utilizes IBM\\'s AI governance capabilities to support organizations in implementing comprehensive AI lifecycle governance. This helps them manage risks and maintain compliance with evolving AI and industry regulations. The platform allows organizations to reduce AI bias by overseeing their AI initiatives, leveraging software automation to enhance risk mitigation, regulatory compliance, and ethical considerations.[10]\\n\\nSee also\\n\\n[edit]\\n\\nIBM Watson\\n\\nGenerative AI\\n\\nLarge language model\\n\\nChatGPT\\n\\nReferences\\n\\n[edit]\\n\\n^ a b c \"IBM Unveils the Watsonx Platform to Power Next-Generation Foundation Models for Business\". IBM Newsroom (Press release).\\n\\n^ Wiggers, Kyle (September 7, 2023). \"IBM rolls out new generative AI features and models\". TechCrunch.\\n\\n^ Horsey, Julian (September 5, 2023). \"IBM Watsonx AI fine tuning platform for business announced\". geeky-gadgets.com.\\n\\n^ \"Anaconda Partners with IBM watsonx to Deliver Enterprise Scale AI Solutions\".\\n\\n^ \"IBM Boosts ESPN Fantasy Football Experience With Watsonx.ai\". Yahoo Finance. September 14, 2023.\\n\\n^ Licata, Patrizia (September 14, 2023). \"WindTre sceglie Watsonx di Ibm per gestire piÃ¹ velocemente le segnalazioni dei clienti\". corrierecomunicazioni.it (in Italian).\\n\\n^ \"IBM Unveils AI Stories with watsonx to Enhance the Digital Fan Experience for 66th Annual GRAMMY AwardsÂ®\". IBM (Press release). Armonk, New York. PRNewswire. January 25, 2024. Retrieved February 5, 2024.\\n\\n^ Brady, Sarah (September 2023). \"IBM launches new generative AI models\". MSN.\\n\\n^ Brady, Sarah (2023). \"IBM to integrate Llama 2 in Watsonx AI\". MSN.\\n\\n^ a b c McDowell, Steve. \"IBM Takes the Reins of Enterprise AI with Watsonx\". Forbes.\\n\\nExternal links\\n\\n[edit]\\n\\nOfficial webpage\\n\\nOfficial introductory video for watsonx AI Prompt Lab\\n\\nv t e IBM History History Mergers and acquisitions PC business acquisition by Lenovo Products Hardware Current Mainframe IBM Z Power microprocessors Power Systems Storage FlashSystem DS8000 Quantum Q System One Q System Two Eagle Osprey Heron Condor Former Blue Gene Cell microprocessors PowerPC Midrange computer Personal Computer Selectric ThinkPad Other alphaWorks Carbon Design System Cloud Cloudant Cognos Analytics Connections Criminal Reduction Utilising Statistical History Fortran ILOG Information Management Software Lotus Software Mainframe operating systems Mashup Center Planning Analytics PureQuery Quantum Platform Qiskit OpenQASM Rational Software SPSS Tivoli Software Service Automation Manager Watson Watsonx Granite WebSphere Business entities Current Apptio Center for The Business of Government Consulting Promontory Kenexa International subsidiaries India Press Red Hat Research Former AdStar AIM alliance Kaleida Labs Taligent Ambra Computer Cognos EduQuest Kyndryl Lexmark Merative Microelectronics Product Center Science Research Associates Service Bureau The Weather Company ( Weather Underground ) Facilities Towers 1250 RenÃ©-LÃ©vesque , Montreal, QC One Atlantic Center , Atlanta, GA Software Labs Rome Software Lab Toronto Software Lab IBM Buildings 330 North Wabash , Chicago, IL Honolulu Seattle Facilities Thomas J. Watson Research Center Hakozaki Facility Yamato Facility Cambridge Scientific Center IBM Hursley Canada Head Office Building IBM Rochester Initiatives Academy of Technology Deep Thunder Developer Develothon Fellow The Great Mind Challenge Linux Technology Center SkillsBuild Smarter Planet Virtual Universe Community World Community Grid Think conference Inventions Automated teller machine Cynefin framework DRAM Electronic keypunch Floppy disk Hard disk drive Magnetic stripe card Relational model Sabre airline reservation system Scanning tunneling microscope Financial swaps Universal Product Code Terminology Big Blue Commercial Processing Workload Customer engineer Globally integrated enterprise e-business Think slogan CEOs Thomas J. Watson (1914â1956) Thomas Watson Jr. (1956â1971) T. Vincent Learson (1971â1973) Frank T. Cary (1973â1981) John R. Opel (1981â1985) John Fellows Akers (1985â1993) Louis V. Gerstner Jr. (1993â2002) Samuel J. Palmisano (2002â2011) Ginni Rometty (2012â2020) Arvind Krishna (since 2020) Board of directors Thomas Buberl David Farr Alex Gorsky Michelle J. Howard Arvind Krishna Andrew Liveris Martha E. Pollack Joseph R. Swedish Peter R. Voser Other A Boy and His Atom Big Blue sports teams American football Rugby union Common Public License / IBM Public License Deep Blue Deep Thought Dynamic infrastructure GlobalFoundries GUIDE International IBM and the Holocaust International chess tournament Lucifer cipher Mathematica IBM Plex SHARE computing ScicomP Unions Category Commons Navigational boxes FOSS Midrange computers Operating systems Personal computers System/360 System/370 Typewriters Vacuum tube computers\\n\\nv t e Differentiable computing General Differentiable programming Information geometry Statistical manifold Automatic differentiation Neuromorphic engineering Pattern recognition Tensor calculus Computational learning theory Inductive bias Concepts Gradient descent SGD Clustering Regression Overfitting Hallucination Adversary Attention Convolution Loss functions Backpropagation Batchnorm Activation Softmax Sigmoid Rectifier Regularization Datasets Augmentation Diffusion Autoregression Applications Machine learning In-context learning Artificial neural network Deep learning Scientific computing Artificial Intelligence Language model Large language model Hardware IPU TPU VPU Memristor SpiNNaker Software libraries TensorFlow PyTorch Keras Theano JAX Flux.jl MindSpore Implementations Audioâvisual AlexNet WaveNet Human image synthesis HWR OCR Speech synthesis Speech recognition Facial recognition AlphaFold Text-to-image models DALL-E Midjourney Stable Diffusion Text-to-video models Sora VideoPoet Whisper Verbal Word2vec Seq2seq BERT Gemini LaMDA Bard NMT Project Debater IBM Watson IBM Watsonx Granite GPT-1 GPT-2 GPT-3 GPT-4 ChatGPT GPT-J Chinchilla AI PaLM BLOOM LLaMA PanGu-Î£ Decisional AlphaGo AlphaZero Q-learning SARSA OpenAI Five Self-driving car MuZero Action selection Auto-GPT Robot control People Yoshua Bengio Alex Graves Ian Goodfellow Stephen Grossberg Demis Hassabis Geoffrey Hinton Yann LeCun Fei-Fei Li Andrew Ng JÃ¼rgen Schmidhuber David Silver Ilya Sutskever Organizations Anthropic EleutherAI Google DeepMind Hugging Face OpenAI Meta AI Mila MIT CSAIL Huawei Architectures Neural Turing machine Differentiable neural computer Transformer Recurrent neural network (RNN) Long short-term memory (LSTM) Gated recurrent unit (GRU) Echo state network Multilayer perceptron (MLP) Convolutional neural network Residual neural network Mamba Autoencoder Variational autoencoder (VAE) Generative adversarial network (GAN) Graph neural network Portals Computer programming Technology Categories Artificial neural networks Machine learning\\n\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=IBM_Watsonx&oldid=1231062979\"\\n\\nCategories:\\n\\nIBM products\\n\\nIBM cloud services\\n\\nData mining and machine learning software\\n\\nChatbots\\n\\nLarge language models\\n\\nGenerative pre-trained transformers\\n\\nInteractive narrative\\n\\nVirtual assistants\\n\\n2023 software\\n\\nHidden categories:\\n\\nCS1 Italian-language sources (it)\\n\\nArticles with short description\\n\\nShort description is different from Wikidata\\n\\nUse American English from May 2023\\n\\nAll Wikipedia articles written in American English\\n\\nUse mdy dates from July 2023\n"
     ]
    }
   ],
   "source": [
    "class Document:\n",
    "    def __init__(self, metadata, page_content):\n",
    "        self.metadata = metadata\n",
    "        self.page_content = page_content\n",
    "\n",
    "URLS_DICTIONARY = {\n",
    "    'watsonx_wiki': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/PWMJ9-Npq9FYNSWrrf99YQ/watsonx.txt',\n",
    "    'ibm_cloud_wiki': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/wxekgOAVRH71dO92DEbwfQ/ibm-cloud.txt',\n",
    "}\n",
    "COLLECTION_NAME = 'ibm_products'\n",
    "\n",
    "documents = []   # List for Document objects\n",
    "\n",
    "for name, url in URLS_DICTIONARY.items():\n",
    "    print(f'Loading from {url}')\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        metadata = {\n",
    "            'source': url, \n",
    "            'name':name\n",
    "        }\n",
    "        page_content = response.text\n",
    "        documents.append(Document(metadata=metadata, page_content=page_content))\n",
    "        print(f'Loaded from {url}')\n",
    "    else:\n",
    "        print(f'Failed to retrieve content from {url}')\n",
    "\n",
    "print(documents[0].metadata)\n",
    "print(documents[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the sample document, it looks like there's a lot of white space and new line characters that we can get rid of. Let's clean that up and add some metadata to our documents, including an ID number and the source of the content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New doc id inserted: {'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/PWMJ9-Npq9FYNSWrrf99YQ/watsonx.txt', 'name': 'watsonx_wiki', 'id': 0}\n",
      "New doc id inserted: {'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/wxekgOAVRH71dO92DEbwfQ/ibm-cloud.txt', 'name': 'ibm_cloud_wiki', 'id': 1}\n",
      "{'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/PWMJ9-Npq9FYNSWrrf99YQ/watsonx.txt', 'name': 'watsonx_wiki', 'id': 0}\n",
      "IBM Watsonx\\n\\nTÃ¼rkÃ§e\\n\\nEdit links\\n\\nFrom Wikipedia, the free encyclopedia\\n\\nAI platform developed by IBM\\n\\nFor the IBM question answering computer system, see IBM Watson.\\n\\nDeveloper(s) IBM Initial release May\\xa09, 2023 ; 14 months ago ( 2023-05-09 ) [1] Written in Python Engine Multiple large language models (LLMs) Platform Cloud computing platforms Type Chatbot AI fine-tuning of large language models Generative pre-trained transformer (GPT) License Proprietary Website www .ibm .com /watsonx\\n\\nPart of a series on Machine learning and data mining Paradigms Supervised learning Unsupervised learning Online learning Batch learning Meta-learning Semi-supervised learning Self-supervised learning Reinforcement learning Curriculum learning Rule-based learning Quantum machine learning Neuromorphic engineering Problems Classification Generative modeling Regression Clustering Dimensionality reduction Density estimation Anomaly detection Data cleaning AutoML Association rules Semantic analysis Structured prediction Feature engineering Feature learning Learning to rank Grammar induction Ontology learning Multimodal learning Supervised learning ( classification â¢ regression ) Apprenticeship learning Decision trees Ensembles Bagging Boosting Random forest k -NN Linear regression Naive Bayes Artificial neural networks Logistic regression Perceptron Relevance vector machine (RVM) Support vector machine (SVM) Clustering BIRCH CURE Hierarchical k -means Fuzzy Expectationâmaximization (EM) DBSCAN OPTICS Mean shift Dimensionality reduction Factor analysis CCA ICA LDA NMF PCA PGD t-SNE SDL Structured prediction Graphical models Bayes net Conditional random field Hidden Markov Anomaly detection RANSAC k -NN Local outlier factor Isolation forest Artificial neural network Autoencoder Deep learning Feedforward neural network Recurrent neural network LSTM GRU ESN reservoir computing Boltzmann machine Restricted GAN Diffusion model SOM Convolutional neural network U-Net LeNet AlexNet DeepDream Neural radiance field Transformer Vision Mamba Spiking neural network Memtransistor Electrochemical RAM (ECRAM) Reinforcement learning Q-learning SARSA Temporal difference (TD) Multi-agent Self-play Learning with humans Active learning Crowdsourcing Human-in-the-loop RLHF Model diagnostics Coefficient of determination Confusion matrix Learning curve ROC curve Mathematical foundations Kernel machines Biasâvariance tradeoff Computational learning theory Empirical risk minimization Occam learning PAC learning Statistical learning VC theory Journals and conferences ECML PKDD NeurIPS ICML ICLR IJCAI ML JMLR Related articles Glossary of artificial intelligence List of datasets for machine-learning research List of datasets in computer vision and image processing Outline of machine learning v t e\\n\\nWatsonx is IBM\\'s commercial generative AI and scientific data platform based on cloud. It offers a studio, data store, and governance toolkit. It supports multiple large language models (LLMs) along with IBM\\'s own Granite.[2][1]\\n\\nThe platform is described as an AI tool tailed to companies and a one which can be customized for customers\\' needs and trained on their confidential data, as client data is said to be not collected by IBM for further training of their models. It is also capable of fine-tuning, an approach which makes training pre-trained models on the newly introduced data possible.[3]\\n\\nHistory\\n\\n[edit]\\n\\nWatsonx was revealed on May 9, 2023, at the annual Think conference of IBM as a platform that includes multiple services. Just like Watson AI computer with the similar name, Watsonx was named after Thomas J. Watson, IBM\\'s founder and first CEO.[1]\\n\\nOn February 13, 2024, Anaconda partnered with IBM to embed its open-source Python packages into Watsonx.[4]\\n\\nWatsonx is currently used at ESPN\\'s Fantasy Football App for managing players\\' performance.[5] It is also used by Italian telecommunications company Wind Tre.[6] Watsonx was used to generate editorial content around nominees during the 66th Annual Grammy Awards.[7]\\n\\nServices\\n\\n[edit]\\n\\nwatsonx.ai\\n\\n[edit]\\n\\nWatsonx.ai is a platform that allows AI developers to leverage a wide range of LLMs under IBM\\'s own Granite series and others such as Facebook\\'s LLaMA-2, free and open-source model Mistral and many others present in Hugging Face community for a diverse set of AI development tasks.[8][9] These models come pre-trained and are designed to excel in various Natural Language Processing (NLP) applications, encompassing question answering, content generation, summarization, text classification, and data extraction. The platform allows fine-tuning with its Tuning Studio, allowing those models to learn the data provided by customers.[10]\\n\\nwatsonx.data\\n\\n[edit]\\n\\nWatsonx.data is a platform designed to assist clients in addressing issues related to data volume, complexity, cost, and governance as they scale their AI workloads. This platform facilitates seamless data access, whether the data is stored in the cloud or on-premises, through a single entry point, offering simple use for users who may not possess technical expertise. This approach prioritizes data security and compliance.[10]\\n\\nwatsonx.governance\\n\\n[edit]\\n\\nWatsonx.governance is a platform that utilizes IBM\\'s AI governance capabilities to support organizations in implementing comprehensive AI lifecycle governance. This helps them manage risks and maintain compliance with evolving AI and industry regulations. The platform allows organizations to reduce AI bias by overseeing their AI initiatives, leveraging software automation to enhance risk mitigation, regulatory compliance, and ethical considerations.[10]\\n\\nSee also\\n\\n[edit]\\n\\nIBM Watson\\n\\nGenerative AI\\n\\nLarge language model\\n\\nChatGPT\\n\\nReferences\\n\\n[edit]\\n\\n^ a b c \"IBM Unveils the Watsonx Platform to Power Next-Generation Foundation Models for Business\". IBM Newsroom (Press release).\\n\\n^ Wiggers, Kyle (September 7, 2023). \"IBM rolls out new generative AI features and models\". TechCrunch.\\n\\n^ Horsey, Julian (September 5, 2023). \"IBM Watsonx AI fine tuning platform for business announced\". geeky-gadgets.com.\\n\\n^ \"Anaconda Partners with IBM watsonx to Deliver Enterprise Scale AI Solutions\".\\n\\n^ \"IBM Boosts ESPN Fantasy Football Experience With Watsonx.ai\". Yahoo Finance. September 14, 2023.\\n\\n^ Licata, Patrizia (September 14, 2023). \"WindTre sceglie Watsonx di Ibm per gestire piÃ¹ velocemente le segnalazioni dei clienti\". corrierecomunicazioni.it (in Italian).\\n\\n^ \"IBM Unveils AI Stories with watsonx to Enhance the Digital Fan Experience for 66th Annual GRAMMY AwardsÂ®\". IBM (Press release). Armonk, New York. PRNewswire. January 25, 2024. Retrieved February 5, 2024.\\n\\n^ Brady, Sarah (September 2023). \"IBM launches new generative AI models\". MSN.\\n\\n^ Brady, Sarah (2023). \"IBM to integrate Llama 2 in Watsonx AI\". MSN.\\n\\n^ a b c McDowell, Steve. \"IBM Takes the Reins of Enterprise AI with Watsonx\". Forbes.\\n\\nExternal links\\n\\n[edit]\\n\\nOfficial webpage\\n\\nOfficial introductory video for watsonx AI Prompt Lab\\n\\nv t e IBM History History Mergers and acquisitions PC business acquisition by Lenovo Products Hardware Current Mainframe IBM Z Power microprocessors Power Systems Storage FlashSystem DS8000 Quantum Q System One Q System Two Eagle Osprey Heron Condor Former Blue Gene Cell microprocessors PowerPC Midrange computer Personal Computer Selectric ThinkPad Other alphaWorks Carbon Design System Cloud Cloudant Cognos Analytics Connections Criminal Reduction Utilising Statistical History Fortran ILOG Information Management Software Lotus Software Mainframe operating systems Mashup Center Planning Analytics PureQuery Quantum Platform Qiskit OpenQASM Rational Software SPSS Tivoli Software Service Automation Manager Watson Watsonx Granite WebSphere Business entities Current Apptio Center for The Business of Government Consulting Promontory Kenexa International subsidiaries India Press Red Hat Research Former AdStar AIM alliance Kaleida Labs Taligent Ambra Computer Cognos EduQuest Kyndryl Lexmark Merative Microelectronics Product Center Science Research Associates Service Bureau The Weather Company ( Weather Underground ) Facilities Towers 1250 RenÃ©-LÃ©vesque , Montreal, QC One Atlantic Center , Atlanta, GA Software Labs Rome Software Lab Toronto Software Lab IBM Buildings 330 North Wabash , Chicago, IL Honolulu Seattle Facilities Thomas J. Watson Research Center Hakozaki Facility Yamato Facility Cambridge Scientific Center IBM Hursley Canada Head Office Building IBM Rochester Initiatives Academy of Technology Deep Thunder Developer Develothon Fellow The Great Mind Challenge Linux Technology Center SkillsBuild Smarter Planet Virtual Universe Community World Community Grid Think conference Inventions Automated teller machine Cynefin framework DRAM Electronic keypunch Floppy disk Hard disk drive Magnetic stripe card Relational model Sabre airline reservation system Scanning tunneling microscope Financial swaps Universal Product Code Terminology Big Blue Commercial Processing Workload Customer engineer Globally integrated enterprise e-business Think slogan CEOs Thomas J. Watson (1914â1956) Thomas Watson Jr. (1956â1971) T. Vincent Learson (1971â1973) Frank T. Cary (1973â1981) John R. Opel (1981â1985) John Fellows Akers (1985â1993) Louis V. Gerstner Jr. (1993â2002) Samuel J. Palmisano (2002â2011) Ginni Rometty (2012â2020) Arvind Krishna (since 2020) Board of directors Thomas Buberl David Farr Alex Gorsky Michelle J. Howard Arvind Krishna Andrew Liveris Martha E. Pollack Joseph R. Swedish Peter R. Voser Other A Boy and His Atom Big Blue sports teams American football Rugby union Common Public License / IBM Public License Deep Blue Deep Thought Dynamic infrastructure GlobalFoundries GUIDE International IBM and the Holocaust International chess tournament Lucifer cipher Mathematica IBM Plex SHARE computing ScicomP Unions Category Commons Navigational boxes FOSS Midrange computers Operating systems Personal computers System/360 System/370 Typewriters Vacuum tube computers\\n\\nv t e Differentiable computing General Differentiable programming Information geometry Statistical manifold Automatic differentiation Neuromorphic engineering Pattern recognition Tensor calculus Computational learning theory Inductive bias Concepts Gradient descent SGD Clustering Regression Overfitting Hallucination Adversary Attention Convolution Loss functions Backpropagation Batchnorm Activation Softmax Sigmoid Rectifier Regularization Datasets Augmentation Diffusion Autoregression Applications Machine learning In-context learning Artificial neural network Deep learning Scientific computing Artificial Intelligence Language model Large language model Hardware IPU TPU VPU Memristor SpiNNaker Software libraries TensorFlow PyTorch Keras Theano JAX Flux.jl MindSpore Implementations Audioâvisual AlexNet WaveNet Human image synthesis HWR OCR Speech synthesis Speech recognition Facial recognition AlphaFold Text-to-image models DALL-E Midjourney Stable Diffusion Text-to-video models Sora VideoPoet Whisper Verbal Word2vec Seq2seq BERT Gemini LaMDA Bard NMT Project Debater IBM Watson IBM Watsonx Granite GPT-1 GPT-2 GPT-3 GPT-4 ChatGPT GPT-J Chinchilla AI PaLM BLOOM LLaMA PanGu-Î£ Decisional AlphaGo AlphaZero Q-learning SARSA OpenAI Five Self-driving car MuZero Action selection Auto-GPT Robot control People Yoshua Bengio Alex Graves Ian Goodfellow Stephen Grossberg Demis Hassabis Geoffrey Hinton Yann LeCun Fei-Fei Li Andrew Ng JÃ¼rgen Schmidhuber David Silver Ilya Sutskever Organizations Anthropic EleutherAI Google DeepMind Hugging Face OpenAI Meta AI Mila MIT CSAIL Huawei Architectures Neural Turing machine Differentiable neural computer Transformer Recurrent neural network (RNN) Long short-term memory (LSTM) Gated recurrent unit (GRU) Echo state network Multilayer perceptron (MLP) Convolutional neural network Residual neural network Mamba Autoencoder Variational autoencoder (VAE) Generative adversarial network (GAN) Graph neural network Portals Computer programming Technology Categories Artificial neural networks Machine learning\\n\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=IBM_Watsonx&oldid=1231062979\"\\n\\nCategories:\\n\\nIBM products\\n\\nIBM cloud services\\n\\nData mining and machine learning software\\n\\nChatbots\\n\\nLarge language models\\n\\nGenerative pre-trained transformers\\n\\nInteractive narrative\\n\\nVirtual assistants\\n\\n2023 software\\n\\nHidden categories:\\n\\nCS1 Italian-language sources (it)\\n\\nArticles with short description\\n\\nShort description is different from Wikidata\\n\\nUse American English from May 2023\\n\\nAll Wikipedia articles written in American English\\n\\nUse mdy dates from July 2023\n"
     ]
    }
   ],
   "source": [
    "doc_id = 0\n",
    "for doc in documents:\n",
    "    doc.page_content = ' '.join(doc.page_content.split())   # remove linebreaks(/n/n) maintaining white spaces\n",
    "    doc.metadata['id'] = doc_id     # add document id to metadata\n",
    "    print(f'New doc id inserted: {doc.metadata}')\n",
    "    doc_id += 1\n",
    "    \n",
    "print(documents[0].metadata)\n",
    "print(documents[0].page_content)  # issue: print function makes '//n//n' look '/n/n', the original '//n//n' cannot be split by split function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`document[0].page_content` still has `//n//n` which is `/n/n` when printed. This is because `split()` cannot recognise `//n//n`. However, this will be removed in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to split up our text into smaller, more manageable pieces known as \"chunks\". LangChain's `RecursiveCharacterTextSplitter` takes a large text and splits it based on a specified chunk size using a predefined set of characters. In order, the default characters are:\n",
    "\n",
    "- \"\\n\\n\" - two new line characters\n",
    "- \"\\n\" - one new line character\n",
    "- \" \" - a space\n",
    "- \"\" - an empty character\n",
    "\n",
    "The process starts by attempting to split the text using the first character, \"\\n\\n.\" If the resulting chunks are still too large, it moves to the next character, \"\\n,\" and tries splitting again. This continues with each character in the set until the chunks are smaller than the specified chunk size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/PWMJ9-Npq9FYNSWrrf99YQ/watsonx.txt', 'name': 'watsonx_wiki', 'id': 0}, page_content='IBM Watsonx\\\\n\\\\nTÃ¼rkÃ§e\\\\n\\\\nEdit links\\\\n\\\\nFrom Wikipedia, the free encyclopedia\\\\n\\\\nAI platform developed by IBM\\\\n\\\\nFor the IBM question answering computer system, see IBM Watson.\\\\n\\\\nDeveloper(s) IBM Initial release May\\\\xa09, 2023 ; 14 months ago ( 2023-05-09 ) [1] Written in Python Engine Multiple large language models (LLMs) Platform Cloud computing platforms Type Chatbot AI fine-tuning of large language models Generative pre-trained transformer (GPT) License Proprietary Website www .ibm .com')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents) # split_documents: iterable, split_text: string\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we choose an embedding model to be trained on our IBM products dataset. The trained embedding model is used to generate embeddings for each data point in the dataset. For text data, popular open-source embedding models include **Word2Vec, GloVe, FastText** or pretrained transformer-based models like **BERT or RoBERTa**. **OpenAIembeddings** may also be used by leveraging the OpenAI embeddings API endpoint, the `langchain_openai` package and getting an `openai_api_key`, however, there is a cost associated with this usage.\n",
    "\n",
    "Unfortunately, because the embedding models are so large, vector embedding often demands significant computational resources, like a GPU. We can greatly lower the costs linked to embedding vectors, while preserving performance and accuracy by using **WatsonxEmbeddings**. We'll use the IBM embeddings model, **Slate**, an encoder-only (RoBERTa-based) model, which while not generative, is fast and effective for many NLP tasks.\n",
    "\n",
    "Alternatively, we can use the [Hugging Face embeddings models](https://python.langchain.com/v0.2/docs/integrations/platforms/huggingface/#embedding-models) via LangChain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = WatsonxEmbeddings(\n",
    "    model_id=EmbeddingTypes.IBM_SLATE_30M_ENG.value,\n",
    "    project_id=project_id,\n",
    "    url=credentials['url']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our content into a local instance of a vector database, using **Chromadb**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=docs, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a quick search of our vector database to test it out! Using `similarity_search_with_score` allows us to return the documents and the distance score of the query to them. The returned distance score is **Euclidean distance**. Therefore, a lower score is better. When querying from Chroma, the default distance function is `l2 (Euclidean)`; other options are `cosine` (cosine distance = 1 - cosine similarity) and `ip (inner product)`.\n",
    "\n",
    "You can adjust `k` to fetch the results to the number you want.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'id': 1, 'name': 'ibm_cloud_wiki', 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/wxekgOAVRH71dO92DEbwfQ/ibm-cloud.txt'}, page_content='Retrieved 2015-05-19.\\\\n\\\\n^ SoftLayer\\\\\\'s new name: IBM Cloud, 2018 [1] IBM, Retrieved 18 January 2019\\\\n\\\\n^ IBM Invests $1B to Deliver Unique Platform-as-a-Service Capabilities to Connect Enterprise Data and Applications to the Cloud (news release), IBM, archived from the original on 2021-01-24\\\\n\\\\n^ \"The best way to develop new ideas at work\", Fortune (article)\\\\n\\\\n^ IBM\\\\\\'s Bluemix PaaS Now Generally Available, eWeek, 1 July 2014. Retrieved 29 October 2018.\\\\n\\\\n^ a b IBM Bluemix finds converts from Amazon,'),\n",
       "  0.406755268573761),\n",
       " (Document(metadata={'id': 1, 'name': 'ibm_cloud_wiki', 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/wxekgOAVRH71dO92DEbwfQ/ibm-cloud.txt'}, page_content='IBM Cloud\\\\n\\\\ní\\x95\\x9cêµ\\xadì\\x96´\\\\n\\\\næ\\x97¥æ\\x9c¬èª\\x9e\\\\n\\\\nEdit links\\\\n\\\\nFrom Wikipedia, the free encyclopedia\\\\n\\\\nCloud computing services provided by IBM\\\\n\\\\nType cloud computing , IaaS , PaaS , cloud services Website www .ibm .com /cloud\\\\n\\\\nIBM Cloud (formerly known as Bluemix) is a set of cloud computing services for business offered by the information technology company IBM.\\\\n\\\\nServices\\\\n\\\\n[edit]\\\\n\\\\nAs of 2021, IBM Cloud contains more than 170 services[1] including compute, storage, networking, database, analytics, machine'),\n",
       "  0.40745809674263),\n",
       " (Document(metadata={'id': 0, 'name': 'watsonx_wiki', 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/PWMJ9-Npq9FYNSWrrf99YQ/watsonx.txt'}, page_content='Lab\\\\n\\\\nv t e IBM History History Mergers and acquisitions PC business acquisition by Lenovo Products Hardware Current Mainframe IBM Z Power microprocessors Power Systems Storage FlashSystem DS8000 Quantum Q System One Q System Two Eagle Osprey Heron Condor Former Blue Gene Cell microprocessors PowerPC Midrange computer Personal Computer Selectric ThinkPad Other alphaWorks Carbon Design System Cloud Cloudant Cognos Analytics Connections Criminal Reduction Utilising Statistical History Fortran ILOG'),\n",
       "  0.41106897592544556),\n",
       " (Document(metadata={'id': 1, 'name': 'ibm_cloud_wiki', 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/wxekgOAVRH71dO92DEbwfQ/ibm-cloud.txt'}, page_content='Spain\".\\\\n\\\\n^ \"How IBM is delivering AI-generated highlights at the US Open\". September 8, 2019. Retrieved November 26, 2021.\\\\n\\\\n^ \"Major European companies select IBM Cloud to drive innovation\". 17 May 2020.\\\\n\\\\n^ Athow, Desire (February 3, 2020). \"Best bare-metal hosting in 2020\". TechRadar. Retrieved 2020-08-05.\\\\n\\\\n^ Moss, Sebastian (February 17, 2021). \"IBM promises to be net zero by 2030\". www.datacenterdynamics.com. Retrieved 2022-01-03.\\\\n\\\\nExternal links\\\\n\\\\n[edit]\\\\n\\\\nOfficial website\\\\n\\\\nv t e Cloud'),\n",
       "  0.4195147156715393)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'What is IBM?'\n",
    "search = vectorstore.similarity_search_with_score(query, k=4)\n",
    "search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: `similarity_search_with_relevance_scores` calculate relevance score depending on the distance parameter—l2, cosine and ip distance are normalised to a score on a scale [0, 1], where 1 means most similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_8_'></a>[Set up a retriever](#toc0_)\n",
    "\n",
    "We'll set up our vector store as a retriever. The retrieved information from the vector store serves as additional context or knowledge that can be used by a generative model.\n",
    "\n",
    "You can also specify search kwargs like `k` (the number of documents to return (Default: 4)) to use when doing retrieval.\n",
    "`search_type` parameter defaults to `similarity`, which runs `similarity_search_with_score`; `mmr` is for [Maximal Marginal Relevance](https://kaustavmukherjee-66179.medium.com/improve-retrieval-of-documents-from-vectordb-using-maximum-marginal-relevance-mmr-for-balancing-f6ae56fb9512); `similarity_score_threshold` runs `similarity_search_with_relevance_scores`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'WatsonxEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7f40df094d40>, search_kwargs={'k': 2})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={'k':2})\n",
    "retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_9_'></a>[Generate a response with a generative model](#toc0_)\n",
    "\n",
    "Finally, we’ll generate a response. The generative model (like GPT-4 or IBM Granite) uses the retrieved information to produce a more accurate and contextually relevant response to our questions about IBM products.\n",
    "\n",
    "First, we'll establish the LLM we're going to use to generate the response. For this tutorial, we'll use **Llama 3**.\n",
    "\n",
    "The available model parameters can be found [here](https://ibm.github.io/watson-machine-learning-sdk/model.html#enums).\n",
    "\n",
    "For more information on model parameters and what they mean, see [Foundation model parameters: decoding and stopping criteria](https://www.ibm.com/docs/en/watsonx/saas?utm_source=skills_network&utm_content=in_lab_content_link&utm_id=Lab-Building+a+RAG+system+for+web+data+using+Llama+3.1-405b_v1_1722347683&topic=lab-model-parameters-prompting).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/llama-3-405b-instruct\"\n",
    "\n",
    "parameters = {\n",
    "    GenParams.DECODING_METHOD: 'greedy',\n",
    "    GenParams.MIN_NEW_TOKENS: 10,\n",
    "    GenParams.MAX_NEW_TOKENS: 512,\n",
    "    GenParams.REPETITION_PENALTY: 1,\n",
    "    GenParams.RETURN_OPTIONS: {'input_tokens': True, 'generated_tokens': True, 'token_logprabs': True, 'token_ranks': True}\n",
    "}\n",
    "\n",
    "llm = WatsonxLLM(\n",
    "    model_id=model_id,\n",
    "    url=credentials.get('url'),\n",
    "    apikey=credentials.get('apikey'),\n",
    "    project_id=project_id,\n",
    "    params=parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll set up a `prompt template` to ask multiple questions. The \"context\" will be derived from our retriever (our vector database) with the relevant documents and the \"question\" will be derived from the user query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Generate a summary of the context that answers the question. Explain the answer in multiple steps if possible.\n",
    "Answer style should match the context. Ideal answer length is 2-3 sentences.\\n\\n{context}\\nQuestion: {question}\\nAnswer:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up a helper function to format the docs accordingly:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can set up a chain with our context, our prompt, and our LLM model. We'll use `StrOutputParser` for parsing the results. The generative model processes the augmented context along with the user's question to produce a response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The chain shows the order of process\n",
    "chain = (\n",
    "    {'context': retriever | format_docs, 'question': RunnablePassthrough()}  # RunnablePassthrough behaves almost like the identity function.\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now ask questions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Watsonx is a cloud-based enterprise artificial intelligence (AI) platform developed by IBM that includes multiple '\n",
      " 'services such as content generation, summarization, text classification, and data extraction. It was named after '\n",
      " \"Thomas J. Watson, IBM's founder and first CEO. The platform allows fine-tuning with its Tuning Studio, enabling \"\n",
      " 'models to learn from customer-provided data.')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chain.invoke('What is watsonx?'), width=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`invoke()` method is widely used method in Langchain. `invoke` works onto each of Langchain classes while a previous output works as an input by `|` operator. To break down how it works, the step-by-step process is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'id': 0, 'name': 'watsonx_wiki', 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/PWMJ9-Npq9FYNSWrrf99YQ/watsonx.txt'}, page_content=\"includes multiple services. Just like Watson AI computer with the similar name, Watsonx was named after Thomas J. Watson, IBM\\\\'s founder and first CEO.[1]\\\\n\\\\nOn February 13, 2024, Anaconda partnered with IBM to embed its open-source Python packages into Watsonx.[4]\\\\n\\\\nWatsonx is currently used at ESPN\\\\'s Fantasy Football App for managing players\\\\' performance.[5] It is also used by Italian telecommunications company Wind Tre.[6] Watsonx was used to generate editorial content around nominees during the 66th\"),\n",
       " Document(metadata={'id': 0, 'name': 'watsonx_wiki', 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/PWMJ9-Npq9FYNSWrrf99YQ/watsonx.txt'}, page_content='content generation, summarization, text classification, and data extraction. The platform allows fine-tuning with its Tuning Studio, allowing those models to learn the data provided by customers.[10]\\\\n\\\\nwatsonx.data\\\\n\\\\n[edit]\\\\n\\\\nWatsonx.data is a platform designed to assist clients in addressing issues related to data volume, complexity, cost, and governance as they scale their AI workloads. This platform facilitates seamless data access, whether the data is stored in the cloud or on-premises, through a')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1a\n",
    "docs = retriever.invoke('What is watsonx?')\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "includes multiple services. Just like Watson AI computer with the similar name, Watsonx was named after Thomas J. Watson, IBM\\'s founder and first CEO.[1]\\n\\nOn February 13, 2024, Anaconda partnered with IBM to embed its open-source Python packages into Watsonx.[4]\\n\\nWatsonx is currently used at ESPN\\'s Fantasy Football App for managing players\\' performance.[5] It is also used by Italian telecommunications company Wind Tre.[6] Watsonx was used to generate editorial content around nominees during the 66th\n",
      "\n",
      "content generation, summarization, text classification, and data extraction. The platform allows fine-tuning with its Tuning Studio, allowing those models to learn the data provided by customers.[10]\\n\\nwatsonx.data\\n\\n[edit]\\n\\nWatsonx.data is a platform designed to assist clients in addressing issues related to data volume, complexity, cost, and governance as they scale their AI workloads. This platform facilitates seamless data access, whether the data is stored in the cloud or on-premises, through a\n"
     ]
    }
   ],
   "source": [
    "# Step 1b\n",
    "context = format_docs(docs)\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is watsonx?'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1c\n",
    "question = RunnablePassthrough().invoke('What is watsonx?')\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content=\"Generate a summary of the context that answers the question. Explain the answer in multiple steps if possible.\\nAnswer style should match the context. Ideal answer length is 2-3 sentences.\\n\\nincludes multiple services. Just like Watson AI computer with the similar name, Watsonx was named after Thomas J. Watson, IBM\\\\'s founder and first CEO.[1]\\\\n\\\\nOn February 13, 2024, Anaconda partnered with IBM to embed its open-source Python packages into Watsonx.[4]\\\\n\\\\nWatsonx is currently used at ESPN\\\\'s Fantasy Football App for managing players\\\\' performance.[5] It is also used by Italian telecommunications company Wind Tre.[6] Watsonx was used to generate editorial content around nominees during the 66th\\n\\ncontent generation, summarization, text classification, and data extraction. The platform allows fine-tuning with its Tuning Studio, allowing those models to learn the data provided by customers.[10]\\\\n\\\\nwatsonx.data\\\\n\\\\n[edit]\\\\n\\\\nWatsonx.data is a platform designed to assist clients in addressing issues related to data volume, complexity, cost, and governance as they scale their AI workloads. This platform facilitates seamless data access, whether the data is stored in the cloud or on-premises, through a\\nQuestion: What is watsonx?\\nAnswer:\")])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2\n",
    "prompt_value = prompt.invoke({'context': context, 'question': question})\n",
    "prompt_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Watsonx is a platform that includes multiple services, such as content generation, summarization, text classification, and data extraction, and is designed to assist clients in addressing issues related to data volume, complexity, cost, and governance as they scale their AI workloads. It was named after Thomas J. Watson, IBM's founder and first CEO. Watsonx is used by various companies, including ESPN and Wind Tre, for managing player performance and generating editorial content.\""
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3\n",
    "answer = llm.invoke(prompt_value)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Watsonx is a platform that includes multiple services, such as content generation, summarization, text classification, and data extraction, and is designed to assist clients in addressing issues related to data volume, complexity, cost, and governance as they scale their AI workloads. It was named after Thomas J. Watson, IBM's founder and first CEO. Watsonx is used by various companies, including ESPN and Wind Tre, for managing player performance and generating editorial content.\""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4\n",
    "StrOutputParser().invoke(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is a generative model answer, the final string could be slightly different each time. Let's try another one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IBM is a technology company with a long history of innovation, dating back to its founding in 1911. The company has undergone significant transformations over the years, including its shift from a hardware-centric business to a more services-oriented company. Today, IBM is a leading provider of cloud computing, artificial intelligence, and IT services, with a strong focus on innovation and sustainability, as evident in its pledge to be net zero by 2030.'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke('Tell me about IBM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IBM Cloud is a set of cloud computing services for business offered by IBM, including compute, storage, networking, database, analytics, and machine learning services. It was formerly known as Bluemix and was rebranded as IBM Cloud in 2017, merging all components and retiring the Bluemix and Softlayer brands. IBM Cloud provides a platform for automating deployment, scaling, and operations of application containers across clusters of hosts.'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke('What is IBM cloud?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "3b0f29881dfa1e4cd235ad6b91fce0450134cdcdf133672b8591a865849dbc3e"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
